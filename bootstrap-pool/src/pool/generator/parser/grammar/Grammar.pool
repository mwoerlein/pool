/*[meta]
mimetype = text/x-pool
author = Marc Woerlein <marc.woerlein@gmx.de>
version = 0.1.0
*/
namespace pool::generator::parser::grammar;

use pool::generator::Symbol;

use pool::generator::regex::Parser as RegexParser;
use pool::generator::regex::fa::NFA as RegexNFA;
use pool::generator::regex::node::List as RegexList;
use pool::generator::tokenizer::dfa::DFA as TokenizerDFA;

use sys::core::String;
use sys::core::anycollection::AnyIterator;
use sys::core::anycollection::AnyList;
use sys::core::anycollection::AnyMap;
use sys::core::anycollection::AnyMapEntryIterator;
use sys::core::anycollection::AnySet;
use sys::stream::IStream;
use sys::stream::OStream;

class Grammar extends sys::core::Object {

    GrammarDefinition definition;
    TokenizerDFA tokenizerDFA;
    
    AnyList terminals; // ArrayList<Symbol>
    AnyList nonTerminals; // ArrayList<Symbol>
    AnyList states; // ArrayList<State>
    State init;

    [] __init() {
        this.terminals = this.createOwn(AnyList:CLASSNAME);
        this.nonTerminals = this.createOwn(AnyList:CLASSNAME);
        this.states = this.createOwn(AnyList:CLASSNAME);
        this.tokenizerDFA = null; // lazy initialization
    }
    
    [Grammar] setDefinition(GrammarDefinition def) { this.own(this.definition = def); return this; }
    [GrammarDefinition] getDefinition() { return this.definition; }
    
    [State] newInitState() { return init = this.newState(); }
    [State] getInitState() { return init; }
    
    [State] newState() {
        State s = this.createOwn(State:CLASSNAME);
        s.setId(states.size());
        states.add(s);
        return s;
    }
    [AnyIterator] states() { return states.iterator(); }
    
    [Symbol] markTerminal(Symbol s) {
        s.setId(terminals.size());
        terminals.add(s);
        return s;
    }
    [int] hasTerminal(Symbol s) { return terminals.contains(s); }
    
    [Symbol] markNonTerminal(Symbol s) {
        s.setId(nonTerminals.size());
        nonTerminals.add(s);
        return s;
    }
    [int] hasNonTerminal(Symbol s) { return nonTerminals.contains(s); }
    
    [AnyIterator] terminals() { return terminals.iterator(); }
    [AnyIterator] nonTerminals() { return nonTerminals.iterator(); }
    [AnyIterator] rules() { return definition.rules(); }
    
    [String] getNamespace() { return definition.getCStringProperty("namespace"); }
    [String] getClassname() { return definition.getCStringProperty("classname"); }
    [String] getTokenizerClassname() { return definition.getCStringProperty("tokenizer"); }
    [String] getExtends() { return definition.getCStringProperty("extends"); }
    
    [TokenizerDFA] getTokenizerDFA() {
        if (!this.tokenizerDFA) {
            this.tokenizerDFA = this.createOwn(TokenizerDFA:CLASSNAME);
            {
                RegexParser parser = this.rt().createInstance(RegexParser:CLASSNAME);
                AnyIterator it = definition.tokens();
                while (it.hasNext()) {
                    Token t = it.next();
                    Symbol s = t.getSymbol();
                    
                    String def = t.getDefinition().subString(1, -1);
                    IStream is = def.toIStream();
                    RegexList l = parser.parse(is, s.getName());

                    this.tokenizerDFA._addTerminal(s, l.toNFA());
                    
                    l.destroy();
                    is.destroy();
                    def.destroy();
                    
                }
                it.destroy();
                parser.destroy();
            }
            this.tokenizerDFA._buildActions();
        }
        return this.tokenizerDFA;
    }
}
